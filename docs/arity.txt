
Test Cases for Source-Level Uncurrying/Arity Raising
====================================================

```
let f = \x -> \y -> e in
f 3 4
==> Uncurry f x y => f (x y)
let f = \x y -> e in
f (3 4)
```

```
let f = \x -> \y -> e in
(f 3 4, f 1)
==> No uncurry: insufficiently saturated
let f = \x -> \y -> e in
(f 3 4, f 1)
```

```
let f = \x -> \y -> \z -> e in
(f 2 3 4, f 1 5)
==> Partial curry: minimum saturation
let f = \x y -> \z -> e in
(f (2 3) 4, f (1 5))
```

```
let f = \b -> if b then \x -> x + x else \x -> x * x in
f true 7
==> No uncurry: significant computation blocks argument list
```

```
let g = \x -> x in
let f = \y -> g in
f 3 4
==> Eta-expand, uncurry
let g = \x -> x in
let f = \y x -> g x in
f (3 4)
```

See "Call Arity" for more discussion of these topics (uncurrying and eta-expansion)

Another topic to note is that if source-level applications are uncurried, their
CPS translation will involve translating and naming `n` temporaries to make the
call.




Vague thoughts, without reference to paper:
===========================================

data Ar = Bot | AtLeast Nat

-- 'ar e n == rho' means that when 'e' is applied to 'n' arguments, the free
-- variables of 'e' are applied to at least 'rho[x]' arguments.
ar :: Expr -> Int -> Map Var Ar

* Use lattice for analysis result:
  ;
* Top element of lattice is `AtLeast 0`. It means that we know nothing about
  the number of arguments.
* Bottom element is kind of like an infinite number of arguments. (Impossible,
  diverges, something you would get from a diverging express like `f x = f x x`)

* rewriting on the fly?


Arity analysis on CPS:

ar : Expr -> Map CoVar CoAr -> Map TmVar Ar

Given arity info for the possible continuations of an expression, use that to
compute the arities applied to each free variable.

type CoAr = [Int] -- number of arguments applied to each value

Source arity analysis is special case where this only one continuation that
accepts only one value.



example: Source adder

let adder : int -> (int -> int) =
  \ (x : int) -> \ (y : int) -> x + y
in
let add3 : int -> int = adder 3 in
add3 5

-- analyze the arity, with these tentative rules
arity (let adder ...) 0 =
  let rho0 = arity(let add3 ...) 0 in
  arity (\ (x : int) ...) (rho0 ! 'adder') `join` rho0
  where
    arity (let add3 ...) 0 =
      let rho1 = arity (add3 5) 0 in
      arity (adder 3) (rho1 ! 'add3') `join` rho1
      where
        arity (add3 5) 0 = arity (add3) 1 = { add3 -> 1 }
      arity (adder 3) (rho1 ! 'adder') = arity (adder 3) 1 = arity (adder) 2 = { adder -> 2 }
    arity (\ (x : int) ...) (rho0 ! 'adder') = arity (\ (x : int) ...) 2
    (hmm. Lost track of notation.)


example: CPS adder

let fun adder (x : int, k0 : (int) => ((int) -> !)) =
  let fun inner (y : int, k1 : (int -> !)) =
    let sum : int = x + y in
    k1 sum
  in
  k0 inner
in
let cont k2 (add3 : (int) => ((int) -> !)) =
  let cont k3 (result : int) =
    halt result
  in
  let arg0 : int = 5 in
  add3 arg1 k3
in
let arg1 : int = 3 in
adder arg1 k2

Assume all functions are non-recursive, so I don't have to worry about
iteration to fixpoint. (yet)

How do I start the analysis/propagate the analysis

It's reasonably obvious in direct style (Call Arity glosses over the
forward-only arity analysis), but not very clear once we're in CPS and already
uncurried (but with 1-argument functions). (Because chains of applications have
been spread out by continuations, so it's hard to count arguments, etc.)



Arity Analysis on Direct-Style IR
=================================

CPS makes analysis hard because most control flow is higher-order. So, to gain
intution, I will now describe rules for arity analysis on a conventional
direct-style IR.

These rules are simplified from [Call Arity], with ideas from [Making a Faster
Curry with Extensional Types]

General idea: given an incoming arity ("this expression is applied to n
arguments"), compute how many arguments are applied to each free variable of
the expression.


arity : Expr -> Arity -> Map Var Arity
arity x n = { x -> n }
arity (e1 e2) n = arity e2 0 <> arity e1 (n+1)
-- can't go negative: still zero arity
-- Annotate function parameters with their inferred arity as well.
arity (λx. e) 0 = let env = arity e 0 in set x.arity = env[x]; env \\ {x}
arity (λx. e) (S n) = let env = arity e n in set x.arity = env[x]; env \\ {x}
-- do branches first
-- scrutinee has incoming arity 0
arity (case e1 of { inl x -> el; inr y -> er }) n = _
-- use body to infer arity of e1
arity (let x = e1 in e2) n = _
-- need to iterate to fixpoint
arity (letrec (xi = ei)+ in e) n = _
arity e n = _

Is this a forward or backward analysis?
My hunch is backward, because 'arity (case e of { alts }) n' basically applies
'n' arguments to each alt, while the scrutinee is always applied to 0 args


Do I need to care about let-floating/duplicated work? I hope not.



-- sample program: 
zipWith :: (a -> b -> c) -> [a] -> [b] -> [c]
zipWith f [] [] = []
zipWith f (x:xs) (y:ys) = f x y : zipWith f xs ys
zipWith f _ _ = []

dot xs ys = sum (zipWith (*) xs ys)

sum = go 0
  where
    go acc [] = acc
    go acc (x:xs) = go (acc+x) xs

-- not fully applied
-- higher-order arity for the inner?
matAdd :: [[Int]] -> [[Int]] -> [[Int]]
matAdd = zipWith (zipWith (+)) 

main :: [Bool]
main = zipWith (||) [False, True, False, True] [False, False, True, True]

main2 :: [[Int]]
main2 = matAdd [[1, 2], [3, 4]] [[5, 6], [7, 8]]

-- from body of main2, matAdd applied to 2 arguments
-- from body of main, zipWith applied to 3 arguments
-- from body of matAdd @ 2 arguments, zipWith applied to 3 arguments (and zipWith applied to 1 argument?)



Hrrm. restrict argument position to variable?
matAdd = let tmp = zipWith (+) in zipWith tmp
from matAdd @ 2, zipWith applied to 3
zipWith @ 3 ==> arg1 @ 2, arg2 @ 0, arg3 @ 0, zipWith @ 3 ==> tmp @ 2
tmp @ 2 ==> zipWith @ 3
zipWith @ 3 ==> arg1 @ 2, arg2 @ 0, arg3 @ 0 ==> (+) @ 2




-- foldl via foldr, and why arity is tricky here
foldr f z = go
  where
    go [] = z
    go (x:xs) = f x (go xs)

foldl f z xs = foldr (\x k -> k . f x) id xs $ z
foldl f z xs = let
    go [] = id
    go (y:ys) = (\x k -> k . f x) y (go ys)
  in
    go xs z
foldl f z xs = let
    go [] = id
    go (y:ys) = go ys . f y
  in
    go xs z

-- same thing, but (.) inlined
foldl f z xs = foldr (\x k b -> k (f x b)) id xs z
foldl f z xs = let
    go [] = id
    go (y:ys) = (\x k b -> k (f x b)) y (go ys)
  in
    go xs z
foldl f z xs = let
    go [] = id
    go (y:ys) = \b -> go ys (f y b)
  in
    go xs z

-- core version

-- non-inlined
foldr = \f -> \z ->
  let
    go = \xs' -> case xs' of {
      [] -> z
      x:xs -> f x (go xs)
    }
  in
    go

foldl f z xs = foldr (\x k b -> k (f x b)) id xs z

-- foldr inlined into foldl
foldl = \f -> \z -> \xs ->
  let
    go = \xs' -> case xs' of {
      [] -> \c -> c
      y:ys -> \b -> go ys (f y b)
    }
  in
    go xs z

non-inlined:
from foldl: foldr @ 4
from foldr @ 4: go @ 2
from go @ 2: z @ 1, f @ 3, go @ 1
foldr/build fusion happens before inlining (foldr needs to still be around for rules to fire)
So foldr must be analyzed separately
So it can't see that there's an extra argument
So it reduces the arity of 'go' and builds a chain of thunks.
-- need higher-order arity to see that go will be called @ 2 again
from go @ 1: z @ 0, f @ 2, go @ 1

inlined version:
foldl @ 3 ==> go @ 2
go @ 2 ==> id @ 1, go @ 2, f @ 2
no problems here. go has arity 2, foldl has arity 3
Okay, one problem: we need to sink the case analysis down past the accumulating
paramter lambda. This is code motion, which I don't know how to do yet.
(a different kind of arity analysis: go always applied to two arguments
==> eta-expand body of \xs' -> case{} into \xs' -> \gen0984 -> case{} gen0984
==> push the application down into each branch of the case
  \xs' -> \gen0984 -> case of { c1 -> e1 gen0984; c2 -> e2 gen0984 }
==> beta-reduce the redexes in each branch.
  \xs' -> \gen0984 -> case xs' of { [] -> gen0984; y:ys -> go ys (f y gen0984) }
This is a place where you have to care about duplicated work, I think.)

foldl f z xs =
  let
    go [] b = b
    go (y:ys) b = go ys (f y b)
  in
    go xs z

foldl = \f ~> \z ~> \xs ~>
  let
    go = \xs' ~> \b ~> case xs' of
      [] -> b
      (y:ys) = go ys (f y b)
  in
    go xs z



Why Higher-Order Arity Analysis is Hard
=======================================

tl;dr: if higher order, analyzing call sites to analyze body means that
analyzing body may require re-examining all call sites. This leads to at least
O(n^2) complexity, probably higher since it is similar to CFA.

example program:

let hof f = f 7 32
in
hof (\x -> \y -> \z -> x+y+z) 5

analysing body concludes that 'hof' is applied to 2 arguments.

We use this to analyze the body. 'f 7 32' is applied to one argument, so 'f' is
applied to 3 arguments.

If we are first order, we stop here. 'hof' can be eta-expanded to two
arguments, but the arguments to 'f' must be passed one at a time, since '\x ->
\y -> \z -> x+y+z' is in argument position and is considered to be applied to 0
arguments.

However, from analyzing the body we know that the first argument ('f') is
applied to 3 arguments. Higher-order arity analysis would tell us to re-examine
the call site, and examine '\x -> \y -> \z -> x+y+z' now with the assumption
that it is applied to 3 arguments. This would let us eta-expand the lambda to
take all three arguments at once.


This specific example is fine, but the lambda is still traversed twice. I can
vaguely imagine a program with lots of nested arguments leading to doubling and
doubling the number of times a specific argument is traversed.

In conclusion, trying to propagate higher-order arity information from call
sites to body and back to call sites leads to bad time complexity.


Furthermore, this has bad implications for arity analysis of CPSed functions,
because all control flow in CPS is higher-order. It may yet be possible to
exploit the second-class nature of continuations to avoid the time complexity
problem, but I have not yet worked out how.
