
I would like to explore row types and extensible records.

The paper "Extensible Records with Scoped Labels" paper (leijen) presents a
type system, but expects to be used with HM-style type inference.

I would like to explore what a fully-explicit typed IR would look like.
(There may be some syntactic differences, because the original paper expects
type inference for assorted mixfix syntaxes)


Big idea: records (more generally, rows) can contain duplicate labels.
Operations usually act on the first (leftmost) occurrence of a label. Record
types are isomorphic when distinct labels can be permuted to make them equal,
but duplicate labels cannot have their order exchanged.

basic operations:
* kind Row
* type {} : Row
* type t : Type, rr : Row |- {l : t | rr} : Row
* empty record: {} : Record {}
* extension: v : t, r : Record rr |- { l = v, r } : Record {l : t | rr}
* projection: r : Record {l : t | rr} |- r.l : t
* restriction: r : Record {l : t | rr} |- r - l : Record rr

pros:
* minimal impact on typechecker
* simple typing rules
* natural integration with row polymorphism

cons:
* restriction operator is common, particularly as part of the derived "field
  update" operation. May need to do O(n) copies often
* runtime representation unclear
* equality of types is more complex than syntactic
  (In particular, consider coercion. If v : A and A == B, then v : B. However,
  for exchanging labels, this might not be a no-op.)



# Runtime Representation of Record Values:

I would also like to explore runtime representations for record values.
Ideally, I would be able to have { field1 : type, field2 : type2, ... } be
represented with

struct ????? {
  struct alloc_header header;
  type1 field1;
  type2 field2;
  ...
};

because that would let field projections be just struct field access.
(Efficient and type-safe) However, I would need to come up with a name for the
record, and deduplicate occurrences of the record type, which is not terribly
convenient.

Also, unboxed and non-pointer-sized fields work out in the obvious manner.
However, this approach doesn't really generalize to row-polymorphic records.


A second approach would be to bring back the "generic product" value representation:

struct generic_product {
  struct alloc_header header;
  uint32_t num_fields;
  struct alloc_header *fields[];
};

With this, all records are represented by a single type. Field projection use
type information at the call site to figure out what offset into 'fields' to
use. (In the same manner, the compiler can figure out how to cast the extracted
field.) However, this cannot easily support unboxed fields. (I don't even *have*
unboxed values yet, but I might want some eventually.)
Note: O(cheap) field access, O(n) extension/restriction


A third approach would be to use a hash table, mapping field names to values.
Similar to 'generic_product', this can only contain boxed values, and the info
from the projection site is used to correctly downcast the value.
I could probably figure out how to do minimal-overhead hash tables that exploit
the fixed number of fields and field names, but in the limit, it's probably the
same as 'generic_product'


Leijen's paper seems to promote a variant of the 'generic_product' approach,
where each field stores a field label and the value, sorted according to some
order on labels. If rows are closed, field offsets can be computed statically.
If rows are open, field offsets cannot be computed statically, but
worker-wrapper transformation can be used to push field offset computations
closer to call sites, where there's more type information.



# Mock-up: sorted span of key-value pairs

```
struct record_field {
  // some string-like type for field labels goes here
  struct label key;
  struct alloc_header *val;
};
struct record {
  struct alloc_header header;
  uint32_t num_fields;
  struct record_field fields[];
};

struct record *allocate_record(uint32_t num_fields, struct record_field *fields) {
  // malloc(header + u32 + size*record_field)
  // assume fields to be sorted?
  // copy fields into record
}

struct alloc_header *project_field(struct record *rec, struct label *l) {
  // binary search for index -- need total order on labels. (compare, leq, or lt)
  ;
  // Project the field value at that index.
}

struct record *extend_record(struct record *rec, struct label *l, struct alloc_header *v) {
  // bsearch to find point of insertion
  // memcpy items before insert point
  // append new value
  // memcpy items after insert point
  ;
}
```

Idea: labels are interned strings. bounded number of labels in a program,
immutable, only need total order.

```
struct label_pool {
  // some sort of interning scheme. Probably buffer & hash table (string -> offset).
};
private buffer interned_strings; // some internal representation. probably global.
struct label {
  // private details, unique identifier of entry in label pool.
}

// Total order on labels.
bool cmp_label_lt(const struct label *l1, const struct label *l2);

void init_labels_pool(void); // create the buffer
void destroy_all_labels(void); // free the buffer
struct label *make_label(size_t len, const char *s); // allocate/dedup label in buffer.
```


```
struct record_field {
  struct label l;
  uint32_t depth;
  struct alloc_header *val;
};
```

A record field consists of a label, how deeply shadowed the label is, and the
value. The shadowing level means that when binary search finds a label with
equal value, we can jump to the topmost value with that label.

```
def lookup_field(rec, l, lo, hi):
  // perform binary search over rec.fields[lo..hi] (inclusive-exclusive) for label 'l'.
  while lo < hi: // if lo == hi, zero-length slice: fail.
    let mid = lo + (hi - lo)/2;
    let field = &rec.fields[mid]
    if (l < field.l):
      hi = mid
      continue
    else if (field.l < l):
      lo = mid
      continue
    else: // total order implies field.l == l
      // Because shadowed labels are all equal, we need to find the outermost
      // label with this value. To solve this, each field contains the shadowing
      // depth of its label. For example, if binary search terminates at the
      // third copy of label 'foo', '.depth' will be '2'. If it by chance did
      // find the first copy, '.depth' would be '0'. Problem solved.
      return mid - fields[mid].depth

  panic!("unreachable: field projections are well-typed")

def project_field(rec, l):
  let idx = lookup_field(rec, l, 0, rec.num_fields)
  return rec.fields[idx].val
```
